{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from transformers import VisionEncoderDecoderConfig, VisionEncoderDecoderModel, ViTFeatureExtractor, AutoTokenizer\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "import re\n",
    "\n",
    "# Define unit symbols and their full names\n",
    "unit_symbols = {\n",
    "    'height': {'cm': 'centimeter', 'mm': 'millimeter', 'in': 'inch', 'm': 'meter', 'ft': 'foot'},\n",
    "    'width': {'cm': 'centimeter', 'mm': 'millimeter', 'in': 'inch', 'm': 'meter', 'ft': 'foot'},\n",
    "    'depth': {'cm': 'centimeter', 'mm': 'millimeter', 'in': 'inch', 'm': 'meter', 'ft': 'foot'},\n",
    "    'item_volume': {'cup': 'cup', 'gal': 'gallon', 'oz': 'ounce', 'ml': 'milliliter', 'ft³': 'cubic foot', 'ft3': 'cubic foot',\n",
    "                    'fl oz': 'fluid ounce', 'dl': 'deciliter', 'in³': 'cubic inch', 'in3': 'cubic inch', 'l': 'liter',\n",
    "                    'qt': 'quart', 'pt': 'pint', 'cl': 'centiliter'},\n",
    "    'wattage': {'W': 'watt', 'w':'watt', 'hp': 'horsepower', 'kW': 'kilowatt', 'kWh': 'kilowatt hour', 'mAh': 'milliampere hour'},\n",
    "    'voltage': {'V': 'volt'},\n",
    "    'item_weight': {'g': 'gram', 'mg': 'milligram', 'kg': 'kilogram', 'oz': 'ounce', 'lb': 'pound',\n",
    "                    't': 'ton', 'µg': 'microgram', 'ml': 'milliliter', 'GB': 'gigabyte', 'gb': 'gigabyte' , 'ct': 'carat',\n",
    "                    'L': 'liter', 'l': 'liter', 'nit': 'nit', 'in': 'inch', 'qt': 'quart', 'W': 'watt',\n",
    "                    'mm': 'millimeter', 'cm': 'centimeter', 'in³': 'cubic inch', 'in3': 'cubic inch'},\n",
    "    'maximum_weight_recommendation': {'g': 'gram', 'mg': 'milligram', 'kg': 'kilogram', 'oz': 'ounce',\n",
    "                                       'lb': 'pound', 't': 'ton', 'µg': 'microgram', 'ml': 'milliliter',\n",
    "                                       'GB': 'gigabyte', 'ct': 'carat', 'L': 'liter', 'nit': 'nit',\n",
    "                                       'in': 'inch', 'qt': 'quart', 'W': 'watt', 'mm': 'millimeter',\n",
    "                                       'cm': 'centimeter', 'in³': 'cubic inch', 'in3': 'cubic inch'}\n",
    "}\n",
    "\n",
    "class ImageTextDataset(Dataset):\n",
    "    def __init__(self, dataframe, feature_extractor, tokenizer, max_target_length=128):\n",
    "        self.dataframe = dataframe\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_target_length = max_target_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataframe)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = self.dataframe.iloc[idx]\n",
    "        image_url = item['image_link']\n",
    "        text = item['text']  \n",
    "\n",
    "        # Download and process image\n",
    "        response = requests.get(image_url)\n",
    "        image = Image.open(BytesIO(response.content)).convert('RGB')\n",
    "        pixel_values = self.feature_extractor(images=image, return_tensors=\"pt\").pixel_values\n",
    "\n",
    "        # Tokenize text\n",
    "        labels = self.tokenizer(text, \n",
    "                                padding=\"max_length\", \n",
    "                                max_length=self.max_target_length,\n",
    "                                truncation=True).input_ids\n",
    "\n",
    "        return {\n",
    "            \"pixel_values\": pixel_values.squeeze(),\n",
    "            \"labels\": torch.tensor(labels)\n",
    "        }\n",
    "\n",
    "def fine_tune_model(train_df, val_df, model_name=\"microsoft/trocr-base-handwritten\", output_dir=\"./fine_tuned_model\"):\n",
    "    # Load pre-trained model and tokenizer\n",
    "    model = VisionEncoderDecoderModel.from_pretrained(model_name)\n",
    "    feature_extractor = ViTFeatureExtractor.from_pretrained(model_name)\n",
    "    tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "    # Prepare datasets\n",
    "    train_dataset = ImageTextDataset(train_df, feature_extractor, tokenizer)\n",
    "    val_dataset = ImageTextDataset(val_df, feature_extractor, tokenizer)\n",
    "\n",
    "    # Define training arguments\n",
    "    training_args = Seq2SeqTrainingArguments(\n",
    "        output_dir=output_dir,\n",
    "        evaluation_strategy=\"epoch\",\n",
    "        learning_rate=5e-5,\n",
    "        per_device_train_batch_size=4,\n",
    "        per_device_eval_batch_size=4,\n",
    "        num_train_epochs=3,\n",
    "        weight_decay=0.01,\n",
    "        save_total_limit=3,\n",
    "    )\n",
    "\n",
    "    # Initialize trainer\n",
    "    trainer = Seq2SeqTrainer(\n",
    "        model=model,\n",
    "        args=training_args,\n",
    "        train_dataset=train_dataset,\n",
    "        eval_dataset=val_dataset,\n",
    "        tokenizer=tokenizer,\n",
    "    )\n",
    "\n",
    "    # Fine-tune the model\n",
    "    trainer.train()\n",
    "\n",
    "    # Save the fine-tuned model\n",
    "    model.save_pretrained(output_dir)\n",
    "    tokenizer.save_pretrained(output_dir)\n",
    "    feature_extractor.save_pretrained(output_dir)\n",
    "\n",
    "    return model, feature_extractor, tokenizer\n",
    "\n",
    "def extract_text_from_image(image_url, model, feature_extractor, tokenizer):\n",
    "    response = requests.get(image_url)\n",
    "    image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n",
    "\n",
    "    pixel_values = feature_extractor(images=image, return_tensors=\"pt\").pixel_values\n",
    "    generated_ids = model.generate(pixel_values)\n",
    "    generated_text = tokenizer.decode(generated_ids[0], skip_special_tokens=True)\n",
    "\n",
    "    return generated_text\n",
    "\n",
    "def find_value_with_symbol(text, entity_name):\n",
    "    if entity_name == 'item_weight':\n",
    "        net_weight_pattern = r'(?:net\\s*(?:wt\\.?|weight)|(?:total\\s*)?weight|wt\\.?|w\\.)\\s*[:()]?\\s*(\\d+(?:[.,]\\d+)?)\\s*([a-zA-Z]+)'\n",
    "        match = re.search(net_weight_pattern, text, re.IGNORECASE)\n",
    "        if match:\n",
    "            value, unit = match.groups()\n",
    "            value = value.replace(',', '.')\n",
    "            formatted_value = f\"{float(value):.1f}\" if '.' not in value else value\n",
    "            \n",
    "            if unit.lower() == 'c':\n",
    "                unit = 'g'\n",
    "            \n",
    "            full_unit_name = next((full for abbr, full in unit_symbols['item_weight'].items() \n",
    "                                   if abbr.lower() == unit.lower()), unit)\n",
    "            \n",
    "            return f\"{formatted_value} {full_unit_name}\"\n",
    "\n",
    "    symbols = unit_symbols.get(entity_name, {})\n",
    "    for symbol, unit_name in symbols.items():\n",
    "        pattern = rf'(\\d+(?:[.,]\\d+)?)\\s*{re.escape(symbol)}'\n",
    "        match = re.search(pattern, text)\n",
    "        if match:\n",
    "            value = match.group(1).replace(',', '.')\n",
    "            formatted_value = f\"{float(value):.1f}\" if '.' not in value else value\n",
    "            return f\"{formatted_value} {unit_name}\"\n",
    "    \n",
    "    return ''\n",
    "\n",
    "def process_dataframe(df, model, feature_extractor, tokenizer):\n",
    "    def process_row(row):\n",
    "        extracted_text = extract_text_from_image(row['image_link'], model, feature_extractor, tokenizer)\n",
    "        return find_value_with_symbol(extracted_text, row['entity_name'])\n",
    "\n",
    "    df['extracted_value'] = df.apply(process_row, axis=1)\n",
    "    return df\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Load your training and validation dataframes\n",
    "    train_df = pd.read_csv('train_data.csv')\n",
    "    val_df = pd.read_csv('val_data.csv')\n",
    "\n",
    "    # Fine-tune the model\n",
    "    model, feature_extractor, tokenizer = fine_tune_model(train_df, val_df)\n",
    "\n",
    "    # Load your test dataframe\n",
    "    test_df = pd.read_csv('test_data.csv')\n",
    "\n",
    "    # Process the test dataframe\n",
    "    result_df = process_dataframe(test_df, model, feature_extractor, tokenizer)\n",
    "\n",
    "    # Save the results\n",
    "    result_df.to_csv('output_results.csv', index=False)\n",
    "    print(\"Processing complete. Results saved to 'output_results.csv'\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
